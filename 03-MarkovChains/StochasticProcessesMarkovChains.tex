MS4217 Stochastic Processes - Markov Chains
%========================================================%
MS4217 Stochastic Processes - Markov Chains
Classification of States
Absorbing states
Classification of Chain
Irreducible Chain
Closed Sets
Ergodic Chains

%========================================================%










%========================================================%
Sample Question
Consider a Markov chain with three states, 1, 2 and 3, and transition matrix 



Question 1: Explain what is meant by the statement that a Markov chain is an irreducible recurrent chain, and show, stating any general results that you assume, that this statement is true for the present chain.
 
Solution: A Markov chain is said to be irreducible if it is possible, with non-zero probability, to move from any state in the state space to any other state. A chain is said to be recurrent if, starting from any state in the space, the probability of eventually returning to that state is 1.

In the present case, because all the transition probabilities are non-zero, it is clearly possible to move from any state to any other state in one step, so the chain is irreducible. It is a general result that all finite irreducible Markov chains are recurrent

Question 2: Find the stationary distribution for this chain.

The stationary distribution (π1, π2, π3) is given by the solution of the equations

	

which reduce to

	

together with the normalisation condition 1+2+3= 1.
It readily follows that the solution is (1,2,3) = (0.25, 0.5 , 0.25).
